---
title: "How to evaluate theory-based hypotheses in a (RI-)CLPM using the GORICA"
author: "Rebecca M. Kuiper"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
fontsize: 14pt
editor_options:
  chunk_output_type: console
---

<style>
body {
  width: 100%;
  margin: 0 auto;
}
</style>


```{r setup, include = FALSE}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
knitr::opts_chunk$set(comment = NA, warning = FALSE)
options(width = 1200) # width console output
```

# Tutorial GORICA and (RI-)CLPM
This is a tutorial for using GORICA for (Random Intercept) Cross-lagged Panel Models ((RI-)CLPMs). The GORICA is an information criterion that can be used to evaluate theory-driven hypotheses.

(RI-)CLPMs are a type of statistical models used in longitudinal data research to analyze the relations between variables measured at multiple time points. Panel data can be analyzed at the construct level and the dimension level. In the construct level model, the focus is on the latent constructs that the observed variables represent. In the dimension model, the focus is on the observed variables themselves, rather than the latent constructs.

Here, two examples are presented for the use of the `goric()` function in the restriktor package to evaluate hypotheses about a CLPM. These are based on the analysis in:  
Snijders, I., Wijnia, L., Kuiper, R. M., Rikers, R. M. J. P., & Loyens, S. M. M. (2021). Relationship quality in higher education and the interplay with student engagement and loyalty. British Journal of Educational Psychology. https://doi.org/10.1111/bjep.12455  
The first example covers analysis at the construct level, while the second example covers analysis at the dimension level.  
Other example files for evaluating (causal dominance) hypotheses in RI-CLPMs can be found on 'https://github.com/rebeccakuiper/Tutorials/tree/main/GORICA%20in%20RI-CLPM'.


## Example 1: Construct Level Analysis

### R packages

First, install and call the `lavaan` library to create a CLPM and the `restriktor` library to load the `goric()` function. If needed, it is possible to view the description of the function with the `?` operator or the `help()` command.

The code presented here also requires the `tidyverse` package for data manipulation.

```{r, results='hide', message=FALSE, warning=FALSE}
# To install restriktor in R:
#if (!require("restriktor")) install.packages("restriktor")

# To install restriktor from github:
# if (!require("devtools")) install.packages("devtools")
# library(devtools) 
# install_github("LeonardV/restriktor")
library(restriktor)

# print docs in the help-tab to view arguments and explanations for the function
#?goric

# To install lavaan in R:
# if (!require("lavaan")) install.packages("lavaan")
library(lavaan)

# To install tidyverse in R:
# if (!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
```


### Data

Upload the data set to the R environment and select the columns used for analysis. The id column is renamed to $ID$ and the code in the data set for missing numbers -999.00 is replaced with `NAs`.

```{r}
data <- read.table("data/CLPM.dat", header = T)
colnames(data)[1] <- "ID"
data <- replace(data , data == -999.00, NA)

data_subset <- select(data, 
                  THT1_SS,
                  TBT1_SS,
                  ACOMT1_SS,
                  SATT1_SS,
                  AB_T1_SS,
                  DE_T1_SS,
                  VI_T1_SS,
                  SLT1_SS,
                  TH_T2_SS,
                  TB_T2_SS,
                  ACOMT2SS,
                  SAT_T2SS,
                  ABT2_SS,
                  DET2_SS,
                  VIT2_SS,
                  SLT2SS)
```


### Measuremnet invariance

Next, we fit the CLPM using `lavaan`. The 'RQ' dimension is split into two sub-dimensions (cf. Snijders et al., 2021).
Model 1 is fit to investigate configural invariance. The model is specified and fit in the following two steps.

```{r}
CLPM_M1 <- '
  
  #####################
  # MEASUREMENT MODEL #
  #####################
  
  # Factor models for RQ1 at 2 waves.
  RQ11 =~ THT1_SS  + TBT1_SS  
  RQ12 =~ TH_T2_SS + TB_T2_SS 
  #RQ1  =~ 1 * RQ11 + 1 * RQ12
  
  # Factor models for RQ2 at 2 waves.
  RQ21 =~ ACOMT1_SS + SATT1_SS
  RQ22 =~ ACOMT2SS  + SAT_T2SS
  #RQ2  =~ 1 * RQ21 + 1 * RQ22
  
  # Factor models for SE at 2 waves.
  SE1 =~ AB_T1_SS + DE_T1_SS + VI_T1_SS
  SE2 =~ ABT2_SS  + DET2_SS  + VIT2_SS

  
  ############
  # DYNAMICS #
  ############
  
  # Specify the lagged effects between the latent variables.
  RQ12 + RQ22 + SE2 + SLT2SS ~ RQ11 + RQ21 + SE1 + SLT1_SS
  
  # Estimate the correlations within the same wave.
  # T1
  RQ11 ~~ RQ21 + SE1 + SLT1_SS
  RQ21 ~~ SE1 + SLT1_SS
  SE1 ~~ SLT1_SS
  # T2
  RQ12 ~~ RQ22 + SE2 + SLT2SS
  RQ22 ~~ SE2 + SLT2SS
  SE2 ~~ SLT2SS

'
```

```{r}
CLPM_M1.fit <- sem(CLPM_M1, data = data_subset, missing = 'ML')
```

When fitting the model R returns the following warning message:

`Warning message:`
`  In lav_object_post_check(object) :`
`  lavaan WARNING: covariance matrix of latent variables`
`is not positive definite;`

So, we use `lavInspect(fit, "cov.lv")` to investigate further.

```{r}
lavInspect(CLPM_M1.fit, "cov.lv")
lavInspect(CLPM_M1.fit, "cor.lv")
```

The correlations between RQ11 & RQ21 and between RQ22 & RQ12 are very high, which is to be expected considered that these two sub-dimensions belong to one dimension. Given that the warning does not point to a model misspecification, we continue the analysis.

```{r}
fitMeasures(CLPM_M1.fit)[c("chisq","df")]
```

The output reports the following:
`chisq      df `
`715.867    78.000 `

Based on these results we continue to Model 2, which investigates weak factorial invariance.

```{r}
CLPM_M2 <- '
  
  #####################
  # MEASUREMENT MODEL #
  #####################
  
  # Factor models for RQ1 at 2 waves.
  RQ11 =~ L1 * THT1_SS  + L2 * TBT1_SS  
  RQ12 =~ L1 * TH_T2_SS + L2 * TB_T2_SS 
  
  # Factor models for RQ2 at 2 waves.
  RQ21 =~ L3 * ACOMT1_SS + L4 * SATT1_SS
  RQ22 =~ L3 * ACOMT2SS  + L4 * SAT_T2SS
  
  # Factor models for SE at 2 waves.
  SE1 =~ L5 * AB_T1_SS + L6 * DE_T1_SS + L7 * VI_T1_SS
  SE2 =~ L5 * ABT2_SS  + L6 * DET2_SS  + L7 * VIT2_SS

  
  ############
  # DYNAMICS #
  ############
  
  # Specify the lagged effects between the latent variables.
  RQ12 + RQ22 + SE2 + SLT2SS ~ RQ11 + RQ21 + SE1 + SLT1_SS
  
  # Estimate the correlations within the same wave.
  # T1
  RQ11 ~~ RQ21 + SE1 + SLT1_SS
  RQ21 ~~ SE1 + SLT1_SS
  SE1 ~~ SLT1_SS
  # T2
  RQ12 ~~ RQ22 + SE2 + SLT2SS
  RQ22 ~~ SE2 + SLT2SS
  SE2 ~~ SLT2SS
  
'
```

```{r}
CLPM_M2.fit <- sem(CLPM_M2, data = data_subset, missing = 'ML')
```

R returns the same warning as before; so, we check the correlations again. 

```{r}
lavInspect(CLPM_M2.fit, "cov.lv")
lavInspect(CLPM_M2.fit, "cor.lv")
```

Again, there is no sign the model needs revision, so we continue.

```{r}
fitMeasures(CLPM_M2.fit)[c("chisq","df")]
```

We obtain these results:
`chisq      df `
`721.021    82.000  `

We perform a Chi-square difference test to check whether Models 1 and 2 differ significantly.

Df = 82 - 78 = 4
Check the constrained factor loadings = 1 + 1 + 2 = 4
Chi-square difference = 721.021 - 715.867 = 5.154
https://www.socscistatistics.com/pvalues/chidistribution.aspx

The P-Value is .271858. The result is not significant at p < .05.

When the chi-square test is non-significant, this implies the factor loadings are not significantly different from each other over time. In other words, we can assume weak factorial invariance holds.

So, we move on to strong factorial invariance with model 3.

```{r}
CLPM_M3 <- '
  
  #####################
  # MEASUREMENT MODEL #
  #####################
  
  # Factor models for RQ1 at 2 waves.
  RQ11 =~ L1 * THT1_SS  + L2 * TBT1_SS  
  RQ12 =~ L1 * TH_T2_SS + L2 * TB_T2_SS 
  
  # Factor models for RQ2 at 2 waves.
  RQ21 =~ L3 * ACOMT1_SS + L4 * SATT1_SS
  RQ22 =~ L3 * ACOMT2SS  + L4 * SAT_T2SS
  
  # Factor models for SE at 2 waves.
  SE1 =~ L5 * AB_T1_SS + L6 * DE_T1_SS + L7 * VI_T1_SS
  SE2 =~ L5 * ABT2_SS  + L6 * DET2_SS  + L7 * VIT2_SS


  # Constrained intercepts over time
  THT1_SS ~ int_th*1 
  TH_T2_SS ~ int_th*1
  TBT1_SS ~ int_tb*1 
  TB_T2_SS ~ int_tb*1 
  ACOMT1_SS ~ int_acom*1 
  ACOMT2SS ~ int_acom*1 
  SATT1_SS ~ int_sat*1 
  SAT_T2SS ~ int_sat*1 
  #
  AB_T1_SS ~ int_ab*1 
  ABT2_SS  ~ int_ab*1 
  DE_T1_SS ~ int_de*1 
  DET2_SS ~ int_de*1 
  VI_T1_SS ~ int_vi*1 
  VIT2_SS ~ int_vi*1 
  #
  SLT1_SS ~ int_sl*1 
  SLT2SS ~ int_sl*1 
  
  
  # Free latent means on t=2
  RQ12 + RQ22 + SE2 + RQ11 + RQ21 + SE1 ~ 1

  
  ############
  # DYNAMICS #
  ############
  
  # Specify the lagged effects between the latent variables.
  RQ12 + RQ22 + SE2 + SLT2SS ~ RQ11 + RQ21 + SE1 + SLT1_SS
  
  # Estimate the correlations within the same wave.
  # T1
  RQ11 ~~ RQ21 + SE1 + SLT1_SS
  RQ21 ~~ SE1 + SLT1_SS
  SE1 ~~ SLT1_SS
  # T2
  RQ12 ~~ RQ22 + SE2 + SLT2SS
  RQ22 ~~ SE2 + SLT2SS
  SE2 ~~ SLT2SS

'
```

```{r}
CLPM_M3.fit <- sem(CLPM_M3, data = data_subset, missing = 'ML')
```

Given the warning, we investigate correlations again.

```{r}
lavInspect(CLPM_M3.fit, "cov.lv")
lavInspect(CLPM_M3.fit, "cor.lv")
```

Then, move on to the results of the model, 
```{r}
fitMeasures(CLPM_M3.fit)[c("chisq","df")]
```
which in this case are:
`chisq       df `
`725.4913    84.0000 `

Because models 2 and 3 are also nested, we perform another Chi-square difference test.

Df = 84 - 82 = 2
Check the constrained parameters = 8 - 6 = 2
Chi-square difference = 725.4913 - 721.021 = 4.4703
https://www.socscistatistics.com/pvalues/chidistribution.aspx

The p-Value is .106976. The result is not significant: p < .05.

If this chi-square difference test is non-significant, this means we can assume that strong factorial invariance holds over time. In that case we could consider investigating whether the means change over time. This is just optional. 

Model 4 investigates strong factorial invariance without free latent means, meaning they are constrained over time). We repeat similar steps as above.

```{r}
CLPM_M4 <- '
  
  #####################
  # MEASUREMENT MODEL #
  #####################
  
  # Factor models for RQ1 at 2 waves.
  RQ11 =~ L1 * THT1_SS  + L2 * TBT1_SS  
  RQ12 =~ L1 * TH_T2_SS + L2 * TB_T2_SS 
  
  # Factor models for RQ2 at 2 waves.
  RQ21 =~ L3 * ACOMT1_SS + L4 * SATT1_SS
  RQ22 =~ L3 * ACOMT2SS  + L4 * SAT_T2SS
  
  # Factor models for SE at 2 waves.
  SE1 =~ L5 * AB_T1_SS + L6 * DE_T1_SS + L7 * VI_T1_SS
  SE2 =~ L5 * ABT2_SS  + L6 * DET2_SS  + L7 * VIT2_SS


  # Constrained intercepts over time
  THT1_SS ~ int_th*1 
  TH_T2_SS ~ int_th*1
  TBT1_SS ~ int_tb*1 
  TB_T2_SS ~ int_tb*1 
  ACOMT1_SS ~ int_acom*1 
  ACOMT2SS ~ int_acom*1 
  SATT1_SS ~ int_sat*1 
  SAT_T2SS ~ int_sat*1 
  #
  AB_T1_SS ~ int_ab*1 
  ABT2_SS  ~ int_ab*1 
  DE_T1_SS ~ int_de*1 
  DET2_SS ~ int_de*1 
  VI_T1_SS ~ int_vi*1 
  VIT2_SS ~ int_vi*1 
  #
  SLT1_SS ~ int_sl*1 
  SLT2SS ~ int_sl*1 
  
  
  ############
  # DYNAMICS #
  ############
  
  # Specify the lagged effects between the latent variables.
  RQ12 + RQ22 + SE2 + SLT2SS ~ RQ11 + RQ21 + SE1 + SLT1_SS
  
  # Estimate the correlations within the same wave.
  # T1
  RQ11 ~~ RQ21 + SE1 + SLT1_SS
  RQ21 ~~ SE1 + SLT1_SS
  SE1 ~~ SLT1_SS
  # T2
  RQ12 ~~ RQ22 + SE2 + SLT2SS
  RQ22 ~~ SE2 + SLT2SS
  SE2 ~~ SLT2SS

'
```

Fit the model:

```{r}
CLPM_M4.fit <- sem(CLPM_M4, data = data_subset, missing = 'ML')
```

Inspect the correlations:

```{r}
lavInspect(CLPM_M4.fit, "cov.lv")
lavInspect(CLPM_M4.fit, "cor.lv")
```

Obtain the results:
```{r}
fitMeasures(CLPM_M4.fit)[c("chisq","df")]
```

We proceed with the Chi-squared difference test with the previous model:  
Df = 90 - 84 = 6
Check the constrained / freed means = 6
Chi-square difference = 757.1568 - 725.4913 = 31.6655
https://www.socscistatistics.com/pvalues/chidistribution.aspx

The P-Value is .000019. The result is significant: p < .05.

Hence, we reject Model 4 and proceed with Model 3 (i.e., strong factorial invariance - with freed means = CLPM_M3.fit).

We can now move further by specifying the lagged effects between the latent variables.


### CLPM

```{r}
clpmModel <- '
  
  #####################
  # MEASUREMENT MODEL #
  #####################
  
  # Factor models for RQ1 at 2 waves.
  RQ11 =~ L1 * THT1_SS  + L2 * TBT1_SS  
  RQ12 =~ L1 * TH_T2_SS + L2 * TB_T2_SS 
  
  # Factor models for RQ2 at 2 waves.
  RQ21 =~ L3 * ACOMT1_SS + L4 * SATT1_SS
  RQ22 =~ L3 * ACOMT2SS  + L4 * SAT_T2SS
  
  # Factor models for SE at 2 waves.
  SE1 =~ L5 * AB_T1_SS + L6 * DE_T1_SS + L7 * VI_T1_SS
  SE2 =~ L5 * ABT2_SS  + L6 * DET2_SS  + L7 * VIT2_SS


  # Constrained intercepts over time
  THT1_SS ~ int_th*1 
  TH_T2_SS ~ int_th*1
  TBT1_SS ~ int_tb*1 
  TB_T2_SS ~ int_tb*1 
  ACOMT1_SS ~ int_acom*1 
  ACOMT2SS ~ int_acom*1 
  SATT1_SS ~ int_sat*1 
  SAT_T2SS ~ int_sat*1 
  #
  AB_T1_SS ~ int_ab*1 
  ABT2_SS  ~ int_ab*1 
  DE_T1_SS ~ int_de*1 
  DET2_SS ~ int_de*1 
  VI_T1_SS ~ int_vi*1 
  VIT2_SS ~ int_vi*1 
  #
  SLT1_SS ~ int_sl*1 
  SLT2SS ~ int_sl*1 
  
  
  # Free latent means on t=2
  RQ12 + RQ22 + SE2 + RQ11 + RQ21 + SE1 ~ 1

  
  ############
  # DYNAMICS #
  ############
  
  # Specify the lagged effects between the latent variables.
  RQ12 ~ Phi11 * RQ11 + Phi12 * RQ21 + Phi13 * SE1 + Phi14 * SLT1_SS
  RQ22 ~ Phi21 * RQ11 + Phi22 * RQ21 + Phi23 * SE1 + Phi24 * SLT1_SS
  #
  SE2 ~ Phi31 * RQ11 + Phi32 * RQ21 + Phi33 * SE1 + Phi34 * SLT1_SS
  SLT2SS ~ Phi41 * RQ11 + Phi42 * RQ21 + Phi43 * SE1 + Phi44 * SLT1_SS
  
  
  # Estimate the correlations within the same wave.
  # T1
  RQ11 ~~ RQ21 + SE1 + SLT1_SS
  RQ21 ~~ SE1 + SLT1_SS
  SE1 ~~ SLT1_SS
  # T2
  RQ12 ~~ RQ22 + SE2 + SLT2SS
  RQ22 ~~ SE2 + SLT2SS
  SE2 ~~ SLT2SS

'
```

Next,we fit the model with the lagged relations:

```{r}
clpmUnc <- sem(clpmModel, data = data_subset, missing = 'ML')
```

Using the `summary()` function we obtain the results of the model fit and estimates. The standardized solution contains the p-values of standardized effects.

```{r}
fitMeasures(clpmUnc)

stdClpmUnc <- standardizedsolution(clpmUnc, type = "std.all", se = TRUE, zstat = TRUE, 
                                   pvalue = TRUE, ci = TRUE, level = 0.95, cov.std = TRUE, 
                                   remove.eq = TRUE, remove.ineq = TRUE, remove.def = FALSE, 
                                   partable = NULL, GLIST = NULL, est = NULL)
stdClpmUnc
```

### GORICA

Next, we select the estimates relative to our hypotheses in order to use the `goric()` function.

```{r}
# indices of estimates of interest
indices <- 37:52

# select estimates from the column 'Std.all' in the results summary above
est <- stdClpmUnc[indices, 'est.std']

names(est) <- c("RQ12_RQ11", "RQ12_RQ21", "RQ12_SE1", "RQ12_SL1", 
                "RQ22_RQ11", "RQ22_RQ21", "RQ22_SE1", "RQ22_SL1", 
                "SE2_RQ11", "SE2_RQ21", "SE2_SE1", "SE2_SL1",
                "SL2_RQ11", "SL2_RQ21", "SL2_SE1", "SL2_SL1"
)

# the covariance matrix for these estimates
vcov <- lavInspect(clpmUnc, "vcov.std.all")[indices-6, indices-6]
```

We specify the hypotheses to test. Note the use of the use of the `abs()` function, that is because we are interested in the size of the relations and we want to compare absolute effects. In cases where the sign of the values is of interest, the `abs()` can be omitted (e.g., estimate_x > .3 or estimate_y < 0).

Here there are two sets of hypotheses, $H1\_Q1$ and $H1\_Q2$, which focus on different relations in the model. The decisions of whether multiple hypotheses should be split in different sets and how to divide them are driven by theory, and depend on what the researchers intend to test. When multiple hypotheses are included in one set, as in $H1\_Q2$, they are handled by the `goric()` function as a whole, not individually.

```{r}
# Q1: Phi_21 > Phi_12
H1_Q1 <- "
abs(RQ22_RQ11) > abs(RQ12_RQ21)
"
#
# Q2
H1_Q2 <- "
abs(SE2_RQ11) > abs(RQ12_SE1);
abs(SL2_RQ11) > abs(RQ12_SL1);
abs(SE2_RQ21) > abs(RQ22_SE1);
abs(SL2_RQ21) > abs(RQ22_SL1)
"
```

We obtain the GORICA results for $H1\_Q1$ and $H1\_Q2$ in two steps. Note the use of `set.seed()` to ensure results are reproducible.

```{r}
set.seed(123)

goricaResults_Q1 <- goric(est, VCOV = vcov, hypotheses = list(H1_Q1=H1_Q1), comparison = "complement", type = "gorica")

goricaResults_Q1
#summary(goricaResults_Q1)
```

The output shows that the order-restricted hypothesis $H1\_Q1$ has 1.7 times more support than its complement.

```{r}
set.seed(123)

goricaResults_Q2 <- goric(est, VCOV = vcov, hypotheses = list(H1_Q2=H1_Q2), comparison = "complement", type = "gorica")

goricaResults_Q2
#summary(goricaResults_Q2)
```

Furthermore, the order-restricted hypothesis $H1\_Q2$ has 1.4 times more support than its complement.

Note that the results hold for the chosen time interval. Hence, the results are time-interval dependent. At the end, more information is given.


## Example 2: Measurement Level Analysis

### R packages

First, install and call the `lavaan` library to create a CLPM and the `restriktor` library to load the `goric()` function. If needed, it is possible to view the description of the function with the `?` operator or the `help()` command.

The code presented here also requires the `tidyverse` package for data manipulation.

```{r, results='hide', message=FALSE, warning=FALSE}
# To install restriktor in R:
#if (!require("restriktor")) install.packages("restriktor")

# To install restriktor from github:
# if (!require("devtools")) install.packages("devtools")
# library(devtools) 
# install_github("LeonardV/restriktor")
library(restriktor)

# print docs in the help-tab to view arguments and explanations for the function
#?goric

# To install lavaan in R:
# if (!require("lavaan")) install.packages("lavaan")
library(lavaan)

# To install tidyverse in R:
# if (!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
```


### Data

Upload the data set to the R environment and select the columns used for analysis. The id column is renamed to $ID$ and the code in the data set for missing numbers -999.00 is replaced with `NAs`.

```{r}
data <- read.table("data/CLPM.dat", header = T)
colnames(data)[1] <- "ID"
data <- replace(data , data == -999.00, NA)

data_subset <- select(data, 
                  THT1_SS,
                  TBT1_SS,
                  ACOMT1_SS,
                  SATT1_SS,
                  AB_T1_SS,
                  DE_T1_SS,
                  VI_T1_SS,
                  SLT1_SS,
                  TH_T2_SS,
                  TB_T2_SS,
                  ACOMT2SS,
                  SAT_T2SS,
                  ABT2_SS,
                  DET2_SS,
                  VIT2_SS,
                  SLT2SS)
```


### CLPM

Next, we fit the CLPM on sum scores using the `lavaan` package. Here we specify all the relations of the model.

```{r}
clpmModel_2 <- '
  
  ############
  # DYNAMICS #
  ############
  
  # Specify the lagged effects between the latent variables.
  TH_T2_SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  TB_T2_SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  ACOMT2SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  SAT_T2SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  #
  ABT2_SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  DET2_SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  VIT2_SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  #
  SLT2SS ~ THT1_SS + TBT1_SS + ACOMT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
  
  
  # Estimate the correlations within the same wave.
  # T1
   ACOMT1_SS ~~ THT1_SS + TBT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
   THT1_SS ~~ TBT1_SS + SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
   TBT1_SS ~~ SATT1_SS + AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
   SATT1_SS ~~ AB_T1_SS + DE_T1_SS + VI_T1_SS + SLT1_SS
   AB_T1_SS ~~ DE_T1_SS + VI_T1_SS + SLT1_SS
   DE_T1_SS ~~ VI_T1_SS + SLT1_SS
   VI_T1_SS ~~ SLT1_SS
   # T2
   TH_T2_SS ~~ TB_T2_SS + SAT_T2SS + ACOMT2SS + ABT2_SS + DET2_SS + VIT2_SS + SLT2SS
   TB_T2_SS ~~ SAT_T2SS + ACOMT2SS + ABT2_SS + DET2_SS + VIT2_SS + SLT2SS
   SAT_T2SS ~~ ACOMT2SS + ABT2_SS + DET2_SS + VIT2_SS + SLT2SS
   ACOMT2SS ~~ ABT2_SS + DET2_SS + VIT2_SS + SLT2SS
   ABT2_SS ~~ DET2_SS + VIT2_SS + SLT2SS
   DET2_SS ~~ VIT2_SS + SLT2SS
   VIT2_SS ~~ SLT2SS
   
'
```

We fit the model using the `sem()` function:

```{r}
clpmUnc_2 <- sem(clpmModel_2, data = data_subset, missing = 'ML')
```

Using the `summary()` function we obtain the results of the model fit and estimates. The standardized solution contains the p-values of standardized effects.

```{r}
fitMeasures(clpmUnc_2)

stdClpmUnc_2 <- standardizedsolution(clpmUnc_2, type = "std.all", se = TRUE, zstat = TRUE, 
                                   pvalue = TRUE, ci = TRUE, level = 0.95, cov.std = TRUE, 
                                   remove.eq = TRUE, remove.ineq = TRUE, remove.def = FALSE, 
                                   partable = NULL, GLIST = NULL, est = NULL)
stdClpmUnc_2
```

In this case the results shows we obtain a 'perfect' model fit, that is because the degrees of freedom are 0, meaning the model is saturated.


### GORICA

We select the estimates relevant to our hypotheses in order to use the `goric()` function.

```{r}
# indices of estimates of interest
indices_2 <- 1:64

# select estimates from the column 'Std.all' in the results summary above
est_2 <- stdClpmUnc_2[indices_2, 'est.std']

names(est_2) <- c("TH2_TH1", "TH2_TB1", "TH2_ACOM1", "TH2_SAT1", "TH2_AB1", "TH2_DE1", "TH2_VI1", "TH2_SL1",
                "TB2_TH1", "TB2_TB1", "TB2_ACOM1", "TB2_SAT1", "TB2_AB1", "TB2_DE1", "TB2_VI1", "TB2_SL1",
                "ACOM2_TH1", "ACOM2_TB1", "ACOM2_ACOM1", "ACOM2_SAT1", "ACOM2_AB1", "ACOM2_DE1", "ACOM2_VI1", "ACOM2_SL1",
                "SAT2_TH1", "SAT2_TB1", "SAT2_ACOM1", "SATM2_SAT1", "SAT2_AB1", "SAT2_DE1", "SAT2_VI1", "SAT2_SL1",
                #
                "AB2_TH1", "AB2_TB1", "AB2_ACOM1", "AB2_SAT1", "AB2_AB1", "AB2_DE1", "AB2_VI1", "AB2_SL1",
                "DE2_TH1", "DE2_TB1", "DE2_ACOM1", "DE2_SAT1", "DE2_AB1", "DE2_DE1", "DE2_VI1", "DE2_SL1",
                "VI2_TH1", "VI2_TB1", "VI2_ACOM1", "VI2_SAT1", "VI2_AB1", "VI2_DE1", "VI2_VI1", "VI2_SL1",
                #
                "SL2_TH1", "SL2_TB1", "SL2_ACOM1", "SL2_SAT1", "SL2_AB1", "SL2_DE1", "SL2_VI1", "SL2_SL1"
)

# the covariance matrix for these estimates
vcov_2 <- lavInspect(clpmUnc_2, "vcov.std.all")[indices_2, indices_2]
```

We then specify the hypotheses to test. Note the use of the use of the `abs()` function; that is because we are interested in the size of the relations and we want to compare absolute effects. In cases where the sign of the values is of interest, the `abs()` can be omitted (e.g., estimate_x > .3 or estimate_y < 0).

Here there are two sets of hypotheses, $H1\_Q1$ and $H1\_Q2$, which focus on different relations in the model. The decisions of whether multiple hypotheses should be split in different sets and how to divide them are driven by theory, and depend on what the researchers intend to test. When multiple hypotheses are included in one set they are handled by the `goric()` function as a whole, not individually.

```{r}
# Q1
H2_Q1 <- "
abs(ACOM2_TH1) > abs(TH2_ACOM1); abs(SAT2_TH1) > abs(TH2_SAT1);
abs(ACOM2_TB1) > abs(TB2_ACOM1); abs(SAT2_TB1) > abs(TB2_SAT1)
"

# Q2
H2_Q2 <- "
abs(AB2_TH1) > abs(TH2_AB1); abs(DE2_TH1) > abs(TH2_DE1); abs(VI2_TH1) > abs(TH2_VI1); abs(SL2_TH1) > abs(TH2_SL1);
abs(AB2_TB1) > abs(TB2_AB1); abs(DE2_TB1) > abs(TB2_DE1); abs(VI2_TB1) > abs(TB2_VI1); abs(SL2_TB1) > abs(TB2_SL1);
abs(AB2_ACOM1) > abs(ACOM2_AB1); abs(DE2_ACOM1) > abs(ACOM2_DE1); abs(VI2_ACOM1) > abs(ACOM2_VI1); abs(SL2_ACOM1) > abs(ACOM2_SL1);
abs(AB2_SAT1) > abs(SAT2_AB1); abs(DE2_SAT1) > abs(SAT2_DE1); abs(VI2_SAT1) > abs(SAT2_VI1); abs(SL2_SAT1) > abs(SAT2_SL1)
"
```

We obtain the GORICA results for $H2\_Q1$ and $H2\_Q2$ in two steps. Note the use of `set.seed()` to ensure results are reproducible.

```{r}
set.seed(123)

goricaResults_H2_Q1 <- goric(est_2, VCOV = vcov_2, hypotheses = list(H2_Q1=H2_Q1), comparison = "complement", type = "gorica")

goricaResults_H2_Q1
#summary(goricaResults_H2_Q1)
```

The output shows that the order-restricted hypothesis $H2\_Q1$ has 2.6 times more support than its complement.

We can proceed in the same manner for $H2\_Q1$; however, because the default method takes too long to calculate the penalty of the GORICA, we use the bootstrap method. When using the bootstrapping the results do not change, but the computation time may decrease. Additionally, using multiple cores can decrease the computation time even more.

```{r}
set.seed(123)

#goricaResults_H2_Q2 <- goric(est_2, VCOV = vcov_2, hypotheses = list(H2_Q2=H2_Q2), comparison = "complement", type = "gorica")
#goricaResults_H2_Q2
##summary(goricaResults_H2_Q2)

# if (!require("parallel")) install.packages("parallel")
library(parallel)

nrCPUcores <- detectCores(all.tests = FALSE, logical = TRUE)

# NB: there are many restrictions, so the code takes longer to run
goricaResults_H2_Q2_b <- goric(est_2, VCOV = vcov_2, hypotheses = list(H2_Q2=H2_Q2), comparison = "complement", type = "gorica", 
                            mix.weights = "boot", parallel = "snow", ncpus = nrCPUcores, mix.bootstrap = 99999)

goricaResults_H2_Q2_b
#summary(goricaResults_H2_Q2_b)
```

The order-restricted hypothesis $H2\_Q2$ has 14 times more support than its complement.

Note that the results hold for the chosen time interval. Hence, the results are time-interval dependent. Next, more information is given.


## Note on time-interval dependency

The parameter estimates in a (RI-)CLPM are time-interval dependent, and thus the GORICA results as well. By using the CTmeta package, one can plot the lagged-effects parameter estimates for different choices of time intervals. Based on this plot (and/or on other information), one can evaluate the hypotheses using the GORICA for different choices of time intervals.  


```{r}
# Install and load packages
#
#library(devtools)
#if (!require("CTmeta")) install_github("rebeccakuiper/CTmeta") ##install_github("rebeccakuiper/CTmeta", force = TRUE)
library(CTmeta)
#?PhiPlot
```


<!-- ```{r} -->
<!-- # Create Phi matrix from this and make Phi plot -->
<!-- Phi <- matrix(est_2, byrow=T, ncol = sqrt(length(est_2))) -->
<!-- #Phi -->
<!-- #PhiPlot(DeltaT = 1, Phi) -->

<!-- # Denote which of the Phi elements we want to plot based on Q1 -->
<!-- WhichEl_Q1 <- matrix(c( -->
<!--   0, 0, 1, 1, 0, 0, 0, 0, -->
<!--   0, 0, 1, 1, 0, 0, 0, 0, -->
<!--   1, 1, 0, 0, 0, 0, 0, 0, -->
<!--   1, 1, 0, 0, 0, 0, 0, 0, -->
<!--   0, 0, 0, 0, 0, 0, 0, 0, -->
<!--   0, 0, 0, 0, 0, 0, 0, 0, -->
<!--   0, 0, 0, 0, 0, 0, 0, 0, -->
<!--   0, 0, 0, 0, 0, 0, 0, 0 -->
<!-- ), ncol = sqrt(length(est_2)))  -->
<!-- PhiPlot(DeltaT = 1, Phi, Min = 0, Max = 10, Step = 0.05, WhichElements = WhichEl_Q1, Labels = NULL, Col = NULL, Lty = NULL, Title = NULL) -->

<!-- # Denote which of the Phi elements we want to plot based on Q2 -->
<!-- WhichEl_Q2 <- matrix(c( -->
<!--   0, 0, 0, 0, 1, 1, 1, 1, -->
<!--   0, 0, 0, 0, 1, 1, 1, 1, -->
<!--   0, 0, 0, 0, 1, 1, 1, 1, -->
<!--   0, 0, 0, 0, 1, 1, 1, 1, -->
<!--   1, 1, 1, 1, 0, 0, 0, 0, -->
<!--   1, 1, 1, 1, 0, 0, 0, 0, -->
<!--   1, 1, 1, 1, 0, 0, 0, 0, -->
<!--   1, 1, 1, 1, 0, 0, 0, 0 -->
<!-- ), ncol = sqrt(length(est_2)))  -->
<!-- PhiPlot(DeltaT = 1, Phi, Min = 0, Max = 10, Step = 0.05, WhichElements = WhichEl_Q2, Labels = NULL, Col = NULL, Lty = NULL, Title = NULL) -->
<!-- ``` -->




